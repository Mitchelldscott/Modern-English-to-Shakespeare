{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ENGL.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tmiAC9JHw_HE",
        "colab_type": "text"
      },
      "source": [
        "# Welcome to the Modern English -> Shakespeare Translator\n",
        "To get things started click on the code cell below and press shift + enter to run it. Be sure the cell finishes running before you try to move on. A number in brackets will appear in the upper left corner of the cell when it is finished."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EFnkKHqxw7Wd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "f290458a-8d0b-4a15-8db0-5bb3b59afe8f"
      },
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import requests\n",
        "from unicodedata import normalize\n",
        "import tensorflow as tf\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from tensorflow.keras.layers import Dense, LSTM, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "import pandas\n",
        "import nltk\n",
        "from collections import Counter\n",
        "nltk.download('punkt')\n",
        "print('Great Job!\\nYou\\'re on your way to becoming a data scientist' )\n",
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "Great Job!\n",
            "You're on your way to becoming a data scientist\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ibCFl0U04aiu",
        "colab_type": "text"
      },
      "source": [
        "# Run the below cell to wipe all collected data\n",
        "If you don't know what you're doing this cell is not for you. Skip to the next section. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_lPSiPRtxWvv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('Modern.txt', 'w') as f:\n",
        "    f.write('')\n",
        "    \n",
        "with open('Original.txt', 'w') as f:\n",
        "    f.write('')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PTGrO5Mf4p6e",
        "colab_type": "text"
      },
      "source": [
        "# The next three cells handle sending webserver requests and saving our precious data\n",
        "If you would like to collect data make sure to run these cells!\n",
        "If you are only here to use the translator (*i.e. you were supplied with data*) this section can be ignored."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j7H8uwi5xdin",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def try_connection(curr_url, headers=None): \n",
        "    try:\n",
        "        if headers:\n",
        "            response = requests.get(curr_url, headers=headers)\n",
        "        else:\n",
        "            response = requests.get(curr_url)\n",
        "    except Exception as e:\n",
        "        self.elog(e,'try_connection')\n",
        "        print('Connection Error With Request: ...')\n",
        "        return None    \n",
        "    for i in range(15):\n",
        "        if response.status_code == 200:\n",
        "            return response\n",
        "        elif response.status_code == 404:\n",
        "            return response       \n",
        "        print(\"Possible Bad Connection. Retrying in 1 min\")\n",
        "        time.sleep(60)\n",
        "        try:\n",
        "            if headers:\n",
        "                response = requests.get(curr_url, headers=headers)\n",
        "            else:\n",
        "                response = requests.get(curr_url)\n",
        "        except Exception as e:\n",
        "            return None\n",
        "    print(response.status_code)   \n",
        "    print(\"Maximum Attempts used: returning response as None\")   \n",
        "    return None"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bH9qBIRfxiY4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def scrape_text(url, extensions=['']):\n",
        "    punctuation = ',/:;-\\\"!?()1234567890'\n",
        "    for ext in extensions:\n",
        "        raw = try_connection(url + str(ext))\n",
        "        print(f'Request for {url + str(ext)} result: {raw}')\n",
        "        soup = BeautifulSoup(raw.content, 'html.parser')\n",
        "        results = soup.find_all('td')\n",
        "        cntr = 0\n",
        "        for item in results:\n",
        "            if cntr:\n",
        "                mod_text = normalize('NFD', item.get_text()).encode('ascii', 'ignore').decode('UTF-8')\n",
        "                tokens = []\n",
        "                for word in mod_text.split():\n",
        "                    tokens.append(''.join(str(letter.lower()) for letter in word if letter not in punctuation))\n",
        "                with open('Modern.txt', 'a+') as f:\n",
        "                    f.write(' '.join(tokens) + '$')\n",
        "                cntr -= 1\n",
        "            else:\n",
        "                orig_text = normalize('NFD', item.get_text()).encode('ascii', 'ignore').decode('UTF-8')\n",
        "                tokens = []\n",
        "                for word in orig_text.split():\n",
        "                    tokens.append(''.join(str(letter.lower()) for letter in word if letter not in punctuation))\n",
        "                with open('Original.txt', 'a+') as f:\n",
        "                    f.write(' '.join(tokens) + '$')\n",
        "                cntr += 1"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nBCFy5AlyLsH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Mid Summer Night's Dream\n",
        "extensions = np.linspace(2, 146, 73, dtype=int)\n",
        "scrape_text('https://www.sparknotes.com/nofear/shakespeare/msnd/page_', extensions=extensions)\n",
        "\n",
        "#Richard iii\n",
        "extensions = np.linspace(2, 342, 171, dtype=int)\n",
        "scrape_text('https://www.sparknotes.com/nofear/shakespeare/richardiii/page_', extensions=extensions)\n",
        "\n",
        "#Romeo and Juliet\n",
        "extensions = np.linspace(2, 260, 130, dtype=int)\n",
        "scrape_text('https://www.sparknotes.com/nofear/shakespeare/romeojuliet/page_', extensions=extensions)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mTAhTlFi5M41",
        "colab_type": "text"
      },
      "source": [
        "# This section reads collected data from the target files and organizes it for the model\n",
        "In order for the model to work These cells must be run. If you forgot how to run just click on the cell and press Shift + Enter. Be sure to wait untill the previous cells finish before running another."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "24R0Nj4CyMV3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_clean_data(file1='Modern.txt', file2='Original.txt'):\n",
        "  with open(file1, 'r') as f:\n",
        "    modern_phrases = f.read().split('$')\n",
        "  with open(file2, 'r') as f:\n",
        "    original_phrases = f.read().split('$')\n",
        "  return (modern_phrases, original_phrases)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u49OOWvukoPd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compile_encoding(corpus):\n",
        "  lookup = {}\n",
        "  encodings = []\n",
        "  length = 1\n",
        "  for phrase in corpus:\n",
        "    words = word_tokenize(phrase)\n",
        "    enc = []\n",
        "    for i in range(330):\n",
        "      if i >= len(words):\n",
        "        enc.append(0)\n",
        "      elif words[i] in lookup:\n",
        "        enc.append(lookup[words[i]])\n",
        "      else:\n",
        "        lookup[words[i]] = length\n",
        "        enc.append(length)\n",
        "        length += 1\n",
        "    encodings.append(np.array([enc]))\n",
        "  return (np.array(encodings), lookup)\n",
        "\n",
        "def encode_phrase(phrase, lookup):\n",
        "  words = word_tokenize(phrase)\n",
        "  print(f'Tokenization {words}')\n",
        "  enc = np.zeros((1,330))\n",
        "  if len(words) > 330:\n",
        "    print('Oversized Input Exiting (max 330 words)')\n",
        "    return\n",
        "  for i, word in enumerate(words):\n",
        "    try:\n",
        "      enc[0][i] = lookup[word]\n",
        "    except:\n",
        "      print(f'{word} is not recognized')\n",
        "  return enc"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yONhC-pAmwBa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "b5432a9a-3114-4671-dd46-940183a2c2c6"
      },
      "source": [
        "modern, original = get_clean_data()\n",
        "modern_data = compile_encoding(modern)\n",
        "original_data = compile_encoding(original)\n",
        "\n",
        "print(f'{len(modern_data[0])} Samples loaded')\n",
        "print(f'{len(modern_data[1])} Total Modern Words found')\n",
        "print(f'{len(original_data[1])} Total original Words found')\n",
        "\n",
        "\n",
        "max = 0\n",
        "ind = -1\n",
        "for i, phrase in enumerate(modern_data[0]):\n",
        "  if phrase[0].shape[0] >= max:\n",
        "    max = phrase[0].shape[0]\n",
        "    ind = i\n",
        "print(f'{ind} Longest modern phrase {max} (by words)')\n",
        "\n",
        "max = 0\n",
        "ind = -1\n",
        "for i, phrase in enumerate(original_data[0]):\n",
        "  if phrase[0].shape[0] >= max:\n",
        "    max = phrase[0].shape[0]\n",
        "    ind = i\n",
        "print(f'{ind} Longest orignal phrase {max} (by words)')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3238 Samples loaded\n",
            "6156 Total Modern Words found\n",
            "7021 Total original Words found\n",
            "3237 Longest modern phrase 330 (by words)\n",
            "3237 Longest orignal phrase 330 (by words)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1B2Y_BAQ5280",
        "colab_type": "text"
      },
      "source": [
        "# This cell contains the models architecture and training cell\n",
        "Again these three cells are for Training the model and need not be tampered with"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ImyxsnBByYVF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model(input_shape=330):\n",
        "  model = keras.Sequential()\n",
        "  model.add(LSTM(units=500, return_sequences = True, input_shape = (1, input_shape)))\n",
        "  model.add(LSTM(units=500, return_sequences=True))\n",
        "  model.add(LSTM(units=500, return_sequences=True))\n",
        "  model.add(LSTM(units=500, return_sequences=True))\n",
        "  model.add(Dense(units=330))\n",
        "  adam = Adam(learning_rate=1e-2)\n",
        "  model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "  model.summary()\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zyB0v5aXsin_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "translator = load_model('drive/My Drive/Models/LSTM-v2-1.h5')"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F0whFy_dsnqj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_data = np.array(modern_data[0])\n",
        "print(input_data.shape)\n",
        "translator.fit(input_data, original_data[0], epochs=2000)\n",
        "translator.save('drive/My Drive/Models/LSTM-v2-1.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qL-ds8i_KkT3",
        "colab_type": "text"
      },
      "source": [
        "### This Cell is where the Translations happen\n",
        "To try a translation run the below cell, enter a phrase in the box and press enter. Make sure to only use lowercase and no punctuation allowed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uRkjTl-r3RJ7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "62195ddb-93a4-4272-c556-39e600514924"
      },
      "source": [
        "translator = load_model('drive/My Drive/Models/LSTM-v2.h5')\n",
        "phrase = input('Enter your modern phrase here: ')\n",
        "encoding = encode_phrase(phrase, modern_data[1])\n",
        "test_data = np.array([encoding])\n",
        "prediction = translator.predict(test_data)\n",
        "s = ''\n",
        "for num in prediction[0][0]:\n",
        "  c = [key for key, value in original_data[1].items() if value == int(num)]\n",
        "  if len(c) > 0:\n",
        "    s += c[0] + ' '\n",
        "print(f'Translation: {s}')"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Enter your modern phrase here: this is lysander\n",
            "Tokenization ['this', 'is', 'lysander']\n",
            "Translation: roaring daughter than turn bosoms judgment quickly old mans nuptial others revenue wanes turn long revenue lingers wanes lysander be philostrate steep our shall bring philostrate and lingers a wanes theseus text happy shall nuptial solemnities wanes my four withering on draws four to stir days draws dowager of enter now oh oh now . heaven text philostrate methinks happy draws fair oh stepdame theseus and nuptial theseus now fair apace our she time or happy hippolyta but nuptial in . hippolyta theseus apace text happy apace theseus now philostrate on but and now hippolyta others text philostrate and others now text with others now philostrate text theseus text now now original now philostrate now original hippolyta others now now now now now now now text now enter now now now theseus now now text now hippolyta original now and others now now now now now now text now now now hippolyta original text now now original original theseus now now theseus enter now enter now enter original text now \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Lgv3V1LIuBj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}